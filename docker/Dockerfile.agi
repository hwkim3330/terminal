# LFM AGI Docker ì´ë¯¸ì§€
FROM nvidia/cuda:12.1-devel-ubuntu22.04

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHONUNBUFFERED=1
ENV CUDA_HOME=/usr/local/cuda
ENV PATH=${CUDA_HOME}/bin:${PATH}
ENV LD_LIBRARY_PATH=${CUDA_HOME}/lib64:${LD_LIBRARY_PATH}

# ìž‘ì—… ë””ë ‰í† ë¦¬ ì„¤ì •
WORKDIR /app

# ì‹œìŠ¤í…œ íŒ¨í‚¤ì§€ ì—…ë°ì´íŠ¸ ë° ê¸°ë³¸ ë„êµ¬ ì„¤ì¹˜
RUN apt-get update && apt-get install -y \
    python3 \
    python3-pip \
    python3-dev \
    git \
    curl \
    wget \
    vim \
    htop \
    build-essential \
    cmake \
    pkg-config \
    libjpeg-dev \
    libpng-dev \
    libtiff-dev \
    libavcodec-dev \
    libavformat-dev \
    libswscale-dev \
    libv4l-dev \
    libxvidcore-dev \
    libx264-dev \
    libgtk-3-dev \
    libatlas-base-dev \
    gfortran \
    && rm -rf /var/lib/apt/lists/*

# Python ì‹¬ë³¼ë¦­ ë§í¬
RUN ln -s /usr/bin/python3 /usr/bin/python

# pip ì—…ê·¸ë ˆì´ë“œ
RUN pip install --upgrade pip setuptools wheel

# PyTorch ì„¤ì¹˜ (CUDA ì§€ì›)
RUN pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# ê¸°ë³¸ Python ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
RUN pip install \
    transformers[torch] \
    accelerate \
    bitsandbytes \
    scipy \
    numpy \
    pandas \
    pillow \
    requests \
    fastapi \
    uvicorn[standard] \
    websockets \
    pydantic \
    python-multipart \
    aiofiles \
    jinja2 \
    python-dotenv \
    tqdm \
    psutil

# í•œêµ­ì–´ NLP ë¼ì´ë¸ŒëŸ¬ë¦¬
RUN pip install \
    konlpy \
    nltk \
    sentencepiece \
    protobuf

# ìµœì í™” ë¼ì´ë¸ŒëŸ¬ë¦¬
RUN pip install \
    onnx \
    onnxruntime-gpu \
    tensorrt \
    nvidia-ml-py3

# ì¶”ê°€ ML ë¼ì´ë¸ŒëŸ¬ë¦¬
RUN pip install \
    scikit-learn \
    matplotlib \
    seaborn \
    plotly \
    jupyter \
    notebook

# ì˜ë£Œ AI ë¼ì´ë¸ŒëŸ¬ë¦¬ (Clara ê´€ë ¨)
RUN pip install \
    monai \
    nibabel \
    pydicom \
    simpleitk

# ìž‘ì—… ë””ë ‰í† ë¦¬ ë° ë°ì´í„° ë³¼ë¥¨ ìƒì„±
RUN mkdir -p /app/lfm_agi \
    /app/data/models \
    /app/data/cache \
    /app/data/datasets \
    /app/logs

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
ENV HF_HOME=/app/data/cache/huggingface
ENV TRANSFORMERS_CACHE=/app/data/cache/transformers
ENV TORCH_HOME=/app/data/cache/torch
ENV CUDA_CACHE_PATH=/app/data/cache/cuda

# í¬íŠ¸ ë…¸ì¶œ
EXPOSE 8000 8001 8888 6006

# LFM AGI ì½”ë“œ ë³µì‚¬
COPY lfm_agi/ /app/lfm_agi/

# ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
RUN echo '#!/bin/bash\n\
echo "ðŸš€ LFM AGI Docker ì»¨í…Œì´ë„ˆ ì‹œìž‘"\n\
echo "ðŸ’» GPU ì •ë³´:"\n\
nvidia-smi --query-gpu=name,memory.total,memory.used --format=csv\n\
echo ""\n\
echo "ðŸ¤– AGI ì‹œìŠ¤í…œ ì‹œìž‘..."\n\
cd /app/lfm_agi\n\
python run_agi.py --mode server --host 0.0.0.0 --port 8000\n\
' > /app/start_agi.sh && chmod +x /app/start_agi.sh

# ê¸°ë³¸ ì‹¤í–‰ ëª…ë ¹
CMD ["/app/start_agi.sh"]